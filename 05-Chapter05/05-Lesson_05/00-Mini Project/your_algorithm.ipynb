{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project - Choose your own Algorithm\n",
    "\n",
    "##### Student Tags\n",
    "\n",
    "Author: Anderson Hitoshi Uyekita    \n",
    "Mini-Project: Support Vector Machine  \n",
    "Course: Data Science - Foundations II  \n",
    "COD: ND111  \n",
    "Date: 16/01/2019    \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Given code](#code)\n",
    "    - [Function](#function)\n",
    "- [N Nearest Neighbors](#part_1)\n",
    "- [Adaboost](#part_2)\n",
    "- [Random Forest](#part_3)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Information\n",
    "\n",
    "This Jupyter Notebook (in Python 2) aims to record all exercise coded to the Support Vector Machine Mini Project.\n",
    "\n",
    "## Introduction <a id='intro'></a>\n",
    "\n",
    "Apply three different algorithm.\n",
    "\n",
    "* KNN\n",
    "* AdaBoost\n",
    "* Random Forest\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given Code <a id='code'></a>\n",
    "\n",
    "Two codes are given.\n",
    "\n",
    "#### Importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
    "\n",
    "    Use a SVM to identify emails from the Enron corpus by their authors:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from email_preprocess_dt import preprocess_dt\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "\n",
    "This one I have edited as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plots(features_train = features_train, labels_train = labels_train):\n",
    "    ### the training data (features_train, labels_train) have both \"fast\" and \"slow\"\n",
    "    ### points mixed together--separate them so we can give them different colors\n",
    "    ### in the scatterplot and identify them visually\n",
    "    grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "    bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "    grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "    bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "    #### initial visualization\n",
    "    plt.xlim(0.0, 1.0)\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.scatter(bumpy_fast, grade_fast, color = \"b\", label=\"fast\")\n",
    "    plt.scatter(grade_slow, bumpy_slow, color = \"r\", label=\"slow\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"bumpiness\")\n",
    "    plt.ylabel(\"grade\")\n",
    "    plt.show()\n",
    "    ################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages.\n",
    "\n",
    "# Importing the K Nearest Neighbors from Scikit learn package.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Importing the AdaBoost from Scikit learn package.\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Importing the Random Forest from Scikit learn package.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importing the Scikit Learn to calcutate the accuracy.\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function <a id='function'></a>\n",
    "\n",
    "This function aims to save lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy.\n",
    "def my_dt(classifier, features_train = features_train, labels_train = labels_train,\n",
    "                      features_test = features_test, labels_test = labels_test, prediction = False):\n",
    "    \"\"\"\n",
    "    This function will calculate the accuracy given the training and test inputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating the classifier.\n",
    "    if classifier == 'knn':\n",
    "        clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif classifier == 'ada':\n",
    "        clf = AdaBoostClassifier()\n",
    "    elif classifier == 'rf':\n",
    "        clf = RandomForestClassifier(n_estimators = 100)\n",
    "    else:\n",
    "        return \"Classifier not recognised!\"\n",
    "        \n",
    "        \n",
    "    # Saving time to compute the elapse time of fitting process.\n",
    "    t0 = time()\n",
    "\n",
    "    # Fitting/Training clf based on training dataframes.\n",
    "    clf.fit(features_train, labels_train)\n",
    "\n",
    "    # Calculating the elapse time of fit calculation.\n",
    "    print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "    # Saving time to compute the elapse time of predicting process. \n",
    "    t1 = time()\n",
    "\n",
    "    # Storing the predict from features_test in pred.\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    # Calculating the elapse time of predicting calculation.\n",
    "    print \"predict time:\", round(time()-t1, 3), \"s\"\n",
    "\n",
    "    # Calculating the accuracy and storing in acc.\n",
    "    acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "    # Printing the acc.\n",
    "    print \"Accuracy:\", round(acc,4)\n",
    "    \n",
    "    # Returning or not\n",
    "    if prediction == True:\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN) <a id='part_1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 4.711 s\n"
     ]
    }
   ],
   "source": [
    "my_dt(classifier = 'knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost <a id='part_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dt(classifier = 'ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest <a id='part_3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dt(classifier = 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing shutil to deal with copy\n",
    "from shutil import copyfile\n",
    "\n",
    "# File name\n",
    "filename = 'your_algorithm.ipynb'\n",
    "\n",
    "# Lesson\n",
    "lesson = '05-Lesson_05'\n",
    "\n",
    "# Directory to make a copy\n",
    "dir_copy = '../../../ND111-Data Science Foundations II/05-Chapter05/' + lesson + '/00-Mini Project/' + filename\n",
    "\n",
    "# Copying file.\n",
    "copyfile(filename, dir_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
