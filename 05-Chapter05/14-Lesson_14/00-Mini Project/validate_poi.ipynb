{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project - Validation\n",
    "\n",
    "##### Student Tags\n",
    "\n",
    "Author: Anderson Hitoshi Uyekita    \n",
    "Mini-Project: Validation  \n",
    "Course: Data Science - Foundations II  \n",
    "COD: ND111  \n",
    "Date: 24/01/2019    \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Given code 1](#code1)\n",
    "- [Exercise 1](#part_i_1)\n",
    "- [Exercise 2](#part_i_2)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information\n",
    "\n",
    "This Jupyter Notebook (in Python 2) aims to create a reproducible archive.\n",
    "\n",
    "## Introduction <a id='intro'></a>\n",
    "\n",
    "In this mini-project, you’ll start from scratch in making a training-testing split in the data. This will be the first step toward your final project, of building a POI identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Your First (Overfit) POI Identifier <a id='part_i_1'></a>\n",
    "\n",
    "You’ll start by building the simplest imaginable (unvalidated) POI identifier. The starter code (validation/validate_poi.py) for this lesson is pretty bare--all it does is read in the data, and format it into lists of labels and features. Create a decision tree classifier (just use the default parameters), train it on all the data (you will fix this in the next part!), and print out the accuracy. THIS IS AN OVERFIT TREE, DO NOT TRUST THIS NUMBER! Nonetheless, what’s the accuracy?\n",
    "\n",
    "<em>From Python 3.3 forward, a change to the order in which dictionary keys are processed was made such that the orders are randomized each time the code is run. This will cause some compatibility problems with the graders and project code, which were run under Python 2.7. To correct for this, add the following argument to the featureFormat call on line 25 of validate_poi.py:\n",
    "\n",
    "sort_keys = '../tools/python2_lesson13_keys.pkl'\n",
    "\n",
    "This will open up a file in the tools folder with the Python 2 key order.\n",
    "\n",
    "Note: If you are not getting the results expected by the grader, then you may want to check the file tools/feature_format.py. Due to changes in the final project, some file changes have affected the numbers output on this assignment as written. Check that you have the most recent version of the file from the repository, such that the featureFormat has a default parameter for sort_keys = False and that keys = dictionary.keys() results.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the validation mini-project.\n",
    "    The first step toward building your POI identifier!\n",
    "\n",
    "    Start by loading/formatting the data\n",
    "\n",
    "    After that, it's not our code anymore--it's yours!\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "data_dict = pickle.load(open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "### first element is our labels, any added elements are predictor\n",
    "### features. Keep this the same for the mini-project, but you'll\n",
    "### have a different feature list when you do the final project.\n",
    "features_list = [\"poi\", \"salary\"]\n",
    "\n",
    "data = featureFormat(data_dict, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### it's all yours from here forward!  \n",
    "\n",
    "# Importing the Scikit Learn Decision Tree Module.\n",
    "from sklearn import tree\n",
    "\n",
    "# Creating the Classifier.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fitting/Training with ALL observations.\n",
    "clf = clf.fit(features, labels)\n",
    "\n",
    "# Predicting using the same dataset. OVERFITTING!!\n",
    "pred = clf.predict(features)\n",
    "\n",
    "# Importing numpy.\n",
    "import numpy as np\n",
    "\n",
    "# Importing the Accuracy module.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculating the accuracy of the overfitted model.\n",
    "acc = accuracy_score(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9894736842105263\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy:\", acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**What is the accuracy of your first (overfit) POI identifier?**\n",
    "\n",
    "98.95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Deploying a Training/Testing Regime <a id='part_i_2'></a>\n",
    "\n",
    "Now you’ll add in training and testing, so that you get a trustworthy accuracy number. Use the train_test_split validation available in sklearn.cross_validation; hold out 30% of the data for testing and set the random_state parameter to 42 (random_state controls which points go into the training set and which are used for testing; setting it to 42 means we know exactly which events are in which set, and can check the results you get). What’s your updated accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the model selection module.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into train and test.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels,test_size=0.30, random_state=42)\n",
    "\n",
    "### it's all yours from here forward!  \n",
    "\n",
    "# Importing the Scikit Learn Decision Tree Module.\n",
    "from sklearn import tree\n",
    "\n",
    "# Creating the Classifier.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fitting/Training with ALL observations.\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "\n",
    "# Predicting using the same dataset. OVERFITTING!!\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "# Importing numpy.\n",
    "import numpy as np\n",
    "\n",
    "# Importing the Accuracy module.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculating the accuracy of the overfitted model.\n",
    "acc = accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241379310344828"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the accuracy\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**What is the accuracy with a testing regime properly deployed?**\n",
    "\n",
    "72.41%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copying file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing shutil to deal with copy\n",
    "from shutil import copyfile\n",
    "\n",
    "# File name\n",
    "filename = 'validate_poi.ipynb'\n",
    "\n",
    "# Lesson\n",
    "lesson = '14-Lesson_14'\n",
    "\n",
    "# Directory to make a copy\n",
    "dir_copy = '../../' + lesson + '/00-Mini Project/' + filename\n",
    "\n",
    "# Copying file.\n",
    "copyfile(filename, dir_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
